{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from gensim.models import word2vec\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import re\n",
    "from collections import Counter\n",
    "import math\n",
    "from random import randint\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拿data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(database,collection):\n",
    "    \n",
    "    \"\"\" 連接DB \n",
    "    \"\"\"    \n",
    "    client = MongoClient('client')\n",
    "    db = client[database]\n",
    "    collection = db[collection]\n",
    "    print(collection.stats)\n",
    "    \"\"\" 拿到data\n",
    "    \"\"\"\n",
    "    cursor = collection.find()\n",
    "    data = pd.DataFrame(list(cursor))\n",
    " \n",
    "    print('finish')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['r.xnet.world:27017'], document_class=dict, tz_aware=False, connect=True), 'foodnext'), 'article.stats')\n",
      "finish\n",
      "Collection(Database(MongoClient(host=['r.xnet.world:27017'], document_class=dict, tz_aware=False, connect=True), 'foodnext'), 'test.stats')\n",
      "finish\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>description</th>\n",
       "      <th>recList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/cloud/consume/paper/3098764222</td>\n",
       "      <td>「食品冒充」與媒體的「庶民偽裝」 @ 食力foodNEXT‧食事求實的知識頻道</td>\n",
       "      <td>作者＝柏井壽繼連鎖飯店的附屬餐廳公開道歉後，說得誇張一點，幾乎全日本主要的飯店與餐廳都在連續...</td>\n",
       "      <td>繼連鎖飯店的附屬餐廳公開道歉後，說得誇張一點，幾乎全日本主要的飯店與餐廳都在連續舉辦記者會道...</td>\n",
       "      <td>[/science/machining/paper/5739111556, /news/ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/cloud/consume/paper/3098765022</td>\n",
       "      <td>為什麼小小花生米，連續18年抽驗都有事？ @ 食力foodNEXT‧食事求實的知識頻道</td>\n",
       "      <td>撰文=林正文食藥署公布2015年度市售花生製品黃麴毒素檢驗結果，共抽驗218件產品，有七件花...</td>\n",
       "      <td>食藥署公布104年度市售花生製品黃麴毒素檢驗結果，共抽驗218件產品，有七件花生製品的黃麴毒...</td>\n",
       "      <td>[/news/newsnow/paper/4616124369, /news/newsfal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/cloud/consume/paper/3098767727</td>\n",
       "      <td>台灣麵包職人開店經驗分享 @ 食力foodNEXT‧食事求實的知識頻道</td>\n",
       "      <td>作者=田川美由a.開麵包店需要申請哪些文件？需要遵守哪些規定？台灣目前對於麵包店的法規並沒有...</td>\n",
       "      <td>台灣目前對於麵包店的法規並沒有像國外那麼嚴格，但如果有一定的銷售量、想要長期經營，建議至少要...</td>\n",
       "      <td>[/life/placemaking/paper/5852303844, /life/pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/cloud/consume/paper/3098768327</td>\n",
       "      <td>想喝路邊攤的現榨果汁？小心細菌一起喝下肚！！！ @ 食力foodNEXT‧食事求實的知識頻道</td>\n",
       "      <td>撰文＝蕭琮容逛市集與夜市的時候，果汁攤販常常是生意最好的那攤。台灣是水果王國，各式各樣的組合...</td>\n",
       "      <td>路邊的果汁看來是路邊攤相對天然的選擇，但每年各地衛生局的抽檢結果可以發現，路邊的現榨果汁非常...</td>\n",
       "      <td>[/news/newsnation/paper/4357961898, /news/news...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/cloud/consume/paper/3098768527</td>\n",
       "      <td>市面真假蜂蜜充斥，鑑定方法有用嗎？ @ 食力foodNEXT‧食事求實的知識頻道</td>\n",
       "      <td>撰文＝蕭琮容2015年11月中旬台北市衛生局抽驗市面蜂蜜，赫然發現不少假的「純蜜」商品，來源...</td>\n",
       "      <td>市面真假蜜充斥，辨別方法眾說紛紜。到底這些說法的科學依據是什麼呢？一般消費者又該如何在缺乏儀...</td>\n",
       "      <td>[/news/newstrack/paper/3357915296, /science/te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               _id  \\\n",
       "2  /cloud/consume/paper/3098764222   \n",
       "3  /cloud/consume/paper/3098765022   \n",
       "4  /cloud/consume/paper/3098767727   \n",
       "5  /cloud/consume/paper/3098768327   \n",
       "6  /cloud/consume/paper/3098768527   \n",
       "\n",
       "                                            title  \\\n",
       "2         「食品冒充」與媒體的「庶民偽裝」 @ 食力foodNEXT‧食事求實的知識頻道   \n",
       "3     為什麼小小花生米，連續18年抽驗都有事？ @ 食力foodNEXT‧食事求實的知識頻道   \n",
       "4             台灣麵包職人開店經驗分享 @ 食力foodNEXT‧食事求實的知識頻道   \n",
       "5  想喝路邊攤的現榨果汁？小心細菌一起喝下肚！！！ @ 食力foodNEXT‧食事求實的知識頻道   \n",
       "6        市面真假蜂蜜充斥，鑑定方法有用嗎？ @ 食力foodNEXT‧食事求實的知識頻道   \n",
       "\n",
       "                                             content  \\\n",
       "2  作者＝柏井壽繼連鎖飯店的附屬餐廳公開道歉後，說得誇張一點，幾乎全日本主要的飯店與餐廳都在連續...   \n",
       "3  撰文=林正文食藥署公布2015年度市售花生製品黃麴毒素檢驗結果，共抽驗218件產品，有七件花...   \n",
       "4  作者=田川美由a.開麵包店需要申請哪些文件？需要遵守哪些規定？台灣目前對於麵包店的法規並沒有...   \n",
       "5  撰文＝蕭琮容逛市集與夜市的時候，果汁攤販常常是生意最好的那攤。台灣是水果王國，各式各樣的組合...   \n",
       "6  撰文＝蕭琮容2015年11月中旬台北市衛生局抽驗市面蜂蜜，赫然發現不少假的「純蜜」商品，來源...   \n",
       "\n",
       "                                         description  \\\n",
       "2  繼連鎖飯店的附屬餐廳公開道歉後，說得誇張一點，幾乎全日本主要的飯店與餐廳都在連續舉辦記者會道...   \n",
       "3  食藥署公布104年度市售花生製品黃麴毒素檢驗結果，共抽驗218件產品，有七件花生製品的黃麴毒...   \n",
       "4  台灣目前對於麵包店的法規並沒有像國外那麼嚴格，但如果有一定的銷售量、想要長期經營，建議至少要...   \n",
       "5  路邊的果汁看來是路邊攤相對天然的選擇，但每年各地衛生局的抽檢結果可以發現，路邊的現榨果汁非常...   \n",
       "6  市面真假蜜充斥，辨別方法眾說紛紜。到底這些說法的科學依據是什麼呢？一般消費者又該如何在缺乏儀...   \n",
       "\n",
       "                                             recList  \n",
       "2  [/science/machining/paper/5739111556, /news/ne...  \n",
       "3  [/news/newsnow/paper/4616124369, /news/newsfal...  \n",
       "4  [/life/placemaking/paper/5852303844, /life/pla...  \n",
       "5  [/news/newsnation/paper/4357961898, /news/news...  \n",
       "6  [/news/newstrack/paper/3357915296, /science/te...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" article: _id, title, keyword\n",
    "    test: _id, content, cate, recList\n",
    "\"\"\"\n",
    "raw_data = get_data('foodnext','article')\n",
    "raw_data2 = get_data('foodnext','test')\n",
    "data = pd.merge(raw_data,raw_data2,how='left',on='_id')\n",
    "data = data.dropna()\n",
    "data = data.drop(['keyword','cate'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理title和content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_tokenizer(text):\n",
    "\n",
    "    words = jieba.cut(text)\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\Jason\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.610 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "data['title'] = data['title'].apply(lambda x: x.strip('@ 食力foodNEXT‧食事求實的知識頻道'))\n",
    "data['title_tokenized'] = data.loc[:,'title'].apply(jieba_tokenizer)\n",
    "data['title_tokenized'] = data.loc[:,'title_tokenized'].apply(lambda x: re.sub('[#！、，「」（）。《》()【】：？－]','',x))\n",
    "\n",
    "data['content_tokenized'] = data.loc[:,'content'].apply(jieba_tokenizer)\n",
    "data['content_tokenized'] = data.loc[:,'content_tokenized'].apply(lambda x: re.sub('[#！＝=、，「」（）。《》()【】：？－]','',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入廣告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['r.xnet.world:27017'], document_class=dict, tz_aware=False, connect=True), 'product'), 'product.stats')\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 拿data\n",
    "\"\"\"\n",
    "product = get_data('product', 'product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 處理 description\n",
    "\"\"\"\n",
    "product['des_tokenized'] = product.loc[:,'description'].apply(jieba_tokenizer)\n",
    "product['des_tokenized'] = product.loc[:,'des_tokenized'].apply(lambda x: re.sub('[#！、，「」（）。《》()【】：？－～]','',x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 處理 item name\n",
    "\"\"\"\n",
    "product['name_tokenized'] = product.loc[:,'itemName'].apply(jieba_tokenizer)\n",
    "product['name_tokenized'] = product.loc[:,'name_tokenized'].apply(lambda x: re.sub('[#！、，「」（）。《》()【】：？－～]','',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['content_tokenized'].values.tolist()\n",
    "corpus_list = list(map(lambda x : x.split(), corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 用corpus建立模型\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 用corpus建立模型\n",
    "\"\"\"\n",
    "# model = word2vec.Word2Vec(corpus_list,size=300,iter=10,sg=1,hs=0)\n",
    "# model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 將廣告加入原本的corpus建立模型\n",
    "\"\"\"\n",
    "description = product['des_tokenized'].values.tolist()\n",
    "description_list = list(map(lambda x: x.split(), description))\n",
    "corpus_list += description_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(corpus_list,size=300,iter=10,sg=1,hs=0)\n",
    "model.save('word2vec_with_ad.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入權重 $ weight = \\cos \\times count$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(number):\n",
    "    \n",
    "    print(rec.iloc[number,:])\n",
    "    return rec['top10'].values[number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm(w2v_model, words, topn=5):\n",
    "    similar_df = pd.DataFrame()\n",
    "    word_list = []\n",
    "\n",
    "    \"\"\" 用模型產生出相關詞 list\n",
    "    \"\"\"\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(w2v_model.wv.most_similar(word, topn=topn), columns=['word', 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=0)\n",
    "             \n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    \"\"\" 判斷相關詞有沒有在 top10 tags裡面\n",
    "        如果有, 便返回其 id與 title\n",
    "    \"\"\"\n",
    "    recomm = []\n",
    "    counter = []\n",
    "    cos =[]\n",
    "    word_list = similar_df['word'].values\n",
    "    cos_list = similar_df['cos'].values\n",
    "\n",
    "    for i in range(rec.shape[0]):\n",
    "        for j in range(len(word_list)):  \n",
    "            if word_list[j] in rec.top10[i]:\n",
    "                tmp = rec.pageid[i]\n",
    "                tmp2 = cos_list[j]\n",
    "\n",
    "                recomm.append(tmp)\n",
    "                cos.append(tmp2)\n",
    "    \n",
    "    recomm_df = pd.DataFrame({'_id': recomm,'cos': cos})\n",
    "    recomm_df = pd.merge(recomm_df,data,how='left',on='_id')\n",
    "    recomm_df = recomm_df.iloc[:,0:3]\n",
    "    recomm_df['count'] = 1\n",
    "    recomm_df = recomm_df.groupby(['_id','title','cos']).sum().reset_index()\n",
    "    recomm_df['weight'] = recomm_df['cos'] * recomm_df['count']\n",
    "    recomm_df = recomm_df.groupby(['_id','title'])[['weight']].sum().sort_values(['weight'],ascending=False).reset_index()\n",
    "    filter = recomm_df['weight'] < recomm_df.weight.values[0]\n",
    "    recomm_df = recomm_df[filter]\n",
    "    recomm_df = recomm_df.drop_duplicates('weight', 'first', inplace=False)\n",
    "    recomm_df_title = list(set(recomm_df.title))\n",
    " \n",
    "    return recomm_df,recomm_df_title\n",
    "\n",
    "\"\"\" 產生推薦廣告\n",
    "\"\"\"\n",
    "def recomm_ad(w2v_model, words, topn=3):\n",
    "    similar_df = pd.DataFrame()\n",
    "    word_list = []\n",
    "    \n",
    "    \"\"\" 用模型產生出相關詞 list\n",
    "    \"\"\"\n",
    "    for word in words:\n",
    "        try:\n",
    "            similar_words = pd.DataFrame(w2v_model.wv.most_similar(word, topn=topn), columns=[word, 'cos'])\n",
    "            similar_df = pd.concat([similar_df, similar_words], axis=1)\n",
    "            word_list.append(similar_words[word].values.tolist())\n",
    "             \n",
    "        except:\n",
    "            print(word, \"not found in Word2Vec model!\")\n",
    "    \n",
    "    word_list = list(set(list(chain(*word_list))))\n",
    "    \n",
    "    \"\"\" 判斷相關詞有沒有在廣告的名稱內, \n",
    "        如果有, 便返回其 id與 title\n",
    "    \"\"\"\n",
    "    recomm_ad = []\n",
    "    for word in word_list:\n",
    "        for i in range(product.shape[0]):\n",
    "\n",
    "            if word in product.name_tokenized[i]:\n",
    "                tmp = product._id[i]\n",
    "                recomm_ad.append(tmp)\n",
    "                \n",
    "    recomm_ad_df = pd.DataFrame(recomm_ad, columns=['_id'])\n",
    "    recomm_ad_df = pd.merge(recomm_ad_df,product,how='left',on='_id')\n",
    "    recomm_ad_df = recomm_ad_df.loc[:,['_id','itemName']]\n",
    "    recomm_ad_df_title = list(set(recomm_ad_df.itemName))\n",
    " \n",
    "    return recomm_ad_df, recomm_ad_df_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('word2vec_with_ad.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" rec: 用tf-idf建立的top10 tags\n",
    "\"\"\"\n",
    "rec = pd.read_json('c:/Users/Jason/Desktop/rec.json',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pageid                              /issue/paper/4098724121\n",
      "top10     [橄欖油, 冷壓, 粕油, 橄欖, 精製, virgin, olive, 特級, oil, 標準]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 輸入文章編號 0-6129\n",
    "\"\"\"\n",
    "words = corpus(0)\n",
    "\"\"\" model: 使用的model\n",
    "    topn: 要取幾個相關詞 \n",
    "\"\"\"\n",
    "recomm_df, recomm_df_title = recomm(model, words, topn=5)\n",
    "recomm_ad_df, recomm_ad_df_title = recomm_ad(model, words, topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 依照上面表單生成推薦的dataframe\n",
    "* 11篇文章\n",
    "* 插1篇廣告\n",
    "* 如果沒有廣告, 便在補1篇文章\n",
    "* 如果文章不足11篇, 有多少取多少\n",
    "* _id + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_df(recomm_df, recomm_ad_df):\n",
    "    \n",
    "    try:\n",
    "        final_df = pd.DataFrame()\n",
    "        final_df = pd.concat([final_df, recomm_df.iloc[:,:2].head(11)], axis=0)\n",
    "        recomm_ad_df = recomm_ad_df.rename(columns= {'itemName':'title'})\n",
    "        final_df = final_df.append(recomm_ad_df.iloc[0,:])\n",
    "    \n",
    "    except:\n",
    "        final_df = final_df.append(recomm_df.iloc[12,:2])\n",
    "    \n",
    "    final_df = final_df.sample(frac=1).reset_index().drop(['index'],axis=1)\n",
    "    \n",
    "    return final_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.food123.com.tw/site/sku/2029146/%E...</td>\n",
       "      <td>菲律賓冷壓初榨椰子油</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/news/newsnow/paper/4593778376</td>\n",
       "      <td>擔心買到摻假初榨橄欖油？未來品質鑑定有新方式！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/issue/paper/4616127369</td>\n",
       "      <td>如何挑選米？擇米守則解析</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/issue/paper/4739524052</td>\n",
       "      <td>義大利知名橄欖油因農藥殘留自主下架</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/science/scsource/paper/5098100228</td>\n",
       "      <td>米裡面有砷，到底該不該擔心？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/issue/paper/4616125169</td>\n",
       "      <td>義大利人判別橄欖油靠感官也靠科學</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/science/machining/paper/4616175364</td>\n",
       "      <td>標榜冷壓橄欖油就一定比較好嗎？這可未必！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/news/newssafe/paper/4616114762</td>\n",
       "      <td>你家是一瓶油炒天下嗎？ 油品專家教你選對好油！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/news/newsfalse/paper/5975261638</td>\n",
       "      <td>網路上流傳許多芥花油的謠言，是真的嗎？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/issue/paper/5111110318</td>\n",
       "      <td>殘留超標的「標」到底是怎麼來的？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/science/knowledge/paper/5357138093</td>\n",
       "      <td>該如何判斷買到油的品質好壞呢？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/issue/paper/4616116162</td>\n",
       "      <td>王四全：黃豆通過嚴密把關才能煉出好油</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  _id                    title\n",
       "0   https://www.food123.com.tw/site/sku/2029146/%E...               菲律賓冷壓初榨椰子油\n",
       "1                      /news/newsnow/paper/4593778376  擔心買到摻假初榨橄欖油？未來品質鑑定有新方式！\n",
       "2                             /issue/paper/4616127369             如何挑選米？擇米守則解析\n",
       "3                             /issue/paper/4739524052        義大利知名橄欖油因農藥殘留自主下架\n",
       "4                  /science/scsource/paper/5098100228           米裡面有砷，到底該不該擔心？\n",
       "5                             /issue/paper/4616125169         義大利人判別橄欖油靠感官也靠科學\n",
       "6                 /science/machining/paper/4616175364     標榜冷壓橄欖油就一定比較好嗎？這可未必！\n",
       "7                     /news/newssafe/paper/4616114762  你家是一瓶油炒天下嗎？ 油品專家教你選對好油！\n",
       "8                    /news/newsfalse/paper/5975261638      網路上流傳許多芥花油的謠言，是真的嗎？\n",
       "9                             /issue/paper/5111110318         殘留超標的「標」到底是怎麼來的？\n",
       "10                /science/knowledge/paper/5357138093          該如何判斷買到油的品質好壞呢？\n",
       "11                            /issue/paper/4616116162       王四全：黃豆通過嚴密把關才能煉出好油"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = make_final_df(recomm_df, recomm_ad_df)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'NLP'",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
