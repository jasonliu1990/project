{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from itertools import chain\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table 5\n",
    "1. cate_id\n",
    "2. cate_title\n",
    "# table 1\n",
    "1. _id\n",
    "2. article_id\n",
    "3. cate_id\n",
    "4. author\n",
    "5. title\n",
    "6. post: Apr 18  2019 3:33:40 PM\n",
    "7. content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table5():\n",
    "    \n",
    "    \"\"\" table5: 取得cate分類\n",
    "        1. cate_id\n",
    "        2. cate_title\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://today.line.me/TW/pc'\n",
    "    html_doc = requests.get(url).text\n",
    "    html_doc = BeautifulSoup(html_doc, 'html.parser')\n",
    "    cate = html_doc.select('._category a')\n",
    "    \n",
    "    cate_id = []\n",
    "    cate_name = []\n",
    "    for i in range(len(cate)):\n",
    "        tmp1 = re.sub('[a-zA-Z /]', '', cate[i].get('href'))\n",
    "        tmp2 = cate[i].get('title')\n",
    "        cate_id = cate_id + [tmp1]\n",
    "        cate_name = cate_name + [tmp2]\n",
    "        \n",
    "    cate = pd.DataFrame()\n",
    "    cate['cate_id'] = cate_id\n",
    "    cate['cate_name'] = cate_name\n",
    "    print('number of cate: %s' %len(cate))\n",
    "    \n",
    "    return cate\n",
    "\n",
    "def build_url_list():\n",
    "    \n",
    "    \"\"\" 取得所有新聞的url\n",
    "    \"\"\"\n",
    "    \n",
    "    url_main = 'https://today.line.me/TW/pc/main/'\n",
    "    url_main_list = []\n",
    "    for i in range(len(cate)):\n",
    "        tmp = url_main + cate.cate_id[i]\n",
    "        url_main_list.append(tmp)\n",
    "        \n",
    "    url = []\n",
    "    url_list = []\n",
    "\n",
    "    for i in range(len(url_main_list)):\n",
    "        html_doc = requests.get(url_main_list[i]).text\n",
    "        html_doc = BeautifulSoup(html_doc, 'html.parser')   \n",
    "        for j in range(len(html_doc.find_all('a'))):\n",
    "            tmp = html_doc.find_all('a')[j].get('href')\n",
    "            url.append(tmp)\n",
    "    \n",
    "    \"\"\" 拿到href後過濾, 取出要的東西\n",
    "    \"\"\"\n",
    "    url_list.append(url[29:-10])\n",
    "    url_list = list(set(list(chain(*url_list))))\n",
    "    print('number of url: %s' %len(url_list))\n",
    "    \n",
    "    return url_list\n",
    "\n",
    "def build_table1():\n",
    "    \n",
    "    \"\"\" 取得文章內容等資訊\n",
    "        1. url\n",
    "        2. article_id\n",
    "        3. cate_id\n",
    "        4. author\n",
    "        5. title\n",
    "        6. post\n",
    "        7. content\n",
    "    \"\"\"\n",
    "    \n",
    "    header = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.96 Safari/537.36'}\n",
    "\n",
    "    counter = 0\n",
    "    tmp_url=[]\n",
    "    tmp_article_id=[]\n",
    "    tmp_cate_id=[]\n",
    "    tmp_author=[]\n",
    "    tmp_title=[]\n",
    "    tmp_post=[]\n",
    "    tmp_content=[]\n",
    "    \n",
    "    \"\"\" 利用之前的url_list抓取網頁內容\n",
    "        再篩選出所需的資料\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(url_list)):\n",
    "        try:\n",
    "            html_doc = requests.get(url_list[i],headers= header).text\n",
    "            html_doc = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "            title = html_doc.head.title.text\n",
    "            author = html_doc.head.find_all('meta')[3].get('content')\n",
    "            tmp = html_doc.head.find_all('meta')[4].get('content').strip().split(',')\n",
    "            title = tmp[1]\n",
    "            post = tmp[2] + tmp[3]\n",
    "            content = list(map(lambda x : x.text, html_doc.select('.news-content p')))\n",
    "            content = ' '.join(content)\n",
    "            cate_id = html_doc.find_all('script')[1].text.split(';')[0].split('=')[1][2:-1]\n",
    "            article_id = html_doc.find_all('script')[1].text.split(';')[2].split('=')[1][2:-1]\n",
    "            \n",
    "            tmp_url.append(url_list[i])\n",
    "            tmp_article_id.append(article_id)\n",
    "            tmp_cate_id.append(cate_id)\n",
    "            tmp_author.append(author)\n",
    "            tmp_title.append(title)\n",
    "            tmp_post.append(post)\n",
    "            tmp_content.append(content)\n",
    "            \n",
    "            counter +=1\n",
    "            if counter%500 == 0:\n",
    "                print(counter)\n",
    "        except Exception:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "    tmp_dict={\n",
    "        'url':tmp_url,\n",
    "        'article_id':tmp_article_id,\n",
    "        'cate_id':tmp_cate_id,\n",
    "        'author':tmp_author,\n",
    "        'title':tmp_title,\n",
    "        'post':tmp_post,\n",
    "        'content':tmp_content\n",
    "    }\n",
    "    content_table = pd.DataFrame(tmp_dict)\n",
    "    content_table['article_id'] = content_table['article_id'].astype(str)\n",
    "    content_table['cate_id'] = content_table['cate_id'].astype(str)\n",
    "    \n",
    "    \n",
    "    return content_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 拿到cate表, 然後產出所有的url\n",
    "    接著拿到所有的新聞內容\n",
    "\"\"\"\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "cate = build_table5()\n",
    "url_list = build_url_list()\n",
    "content_table = build_table1()\n",
    "end = datetime.datetime.now()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## table 2 + 3\n",
    "1. article_id\n",
    "2. user_id\n",
    "3. comment\n",
    "4. user_id : reply\n",
    "\n",
    "article_id - {user_id} - {comment} - {user_id + reply}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table2():\n",
    "    \n",
    "    \"\"\" 取得所有的評論\n",
    "        1. article_id: 文章id\n",
    "        2. user_id: 留言者照片\n",
    "        3. user_name: 留言者姓名\n",
    "        4. content: 留言內容\n",
    "        5. like: 獲得like\n",
    "        6. dislike: 獲得dislike\n",
    "        7. replyCount: 獲得回覆數\n",
    "        8. commentSn: 留言流水號\n",
    "    \"\"\"\n",
    "\n",
    "    article_id = content_table['article_id'].values\n",
    "\n",
    "    com_url = 'https://api.today.line.me/webapi/comment/list?articleId=68687297&country=TW&replyCount=true&limit=100&direction=DESC&sort=POPULAR'\n",
    "    com_url = com_url \n",
    "    com_url_list = list(map(lambda x: com_url.replace('68687297',str(x)), article_id))\n",
    "    com_list = []\n",
    "    tmp = []\n",
    "    for i in range(len(com_url_list)):\n",
    "        try:\n",
    "            \"\"\" i in range(11) 指範圍設定在前1000則留言(可更改)\n",
    "                如果hasMore = False時, 則跳出迴圈\n",
    "            \"\"\"\n",
    "            j = 0\n",
    "               \n",
    "            while (True):\n",
    "                url = com_url_list[i]\n",
    "                url = url + '&pivot=' + str(j) + '00'\n",
    "                \n",
    "                doc = requests.get(url).text\n",
    "                tmp = json.loads(doc)\n",
    "                com_list.append(tmp)\n",
    "                                \n",
    "                if tmp['result']['comments']['hasMore'] == True:\n",
    "                    \n",
    "                    j += 1\n",
    "                    \n",
    "                else :\n",
    "                   \n",
    "                    break\n",
    "\n",
    "            if i%500 == 0:\n",
    "                print(i)\n",
    "            \n",
    "\n",
    "        except:\n",
    "            print('x')\n",
    "    print('url len: %s'%len(com_url_list))\n",
    "    print('com len: %s'%len(com_list))\n",
    "    \n",
    "    count_tmp = []\n",
    "    article_id_tmp = []\n",
    "    user_id_tmp = []\n",
    "    user_name_tmp = []\n",
    "    content_tmp = []\n",
    "    like_tmp = []\n",
    "    dislike_tmp = []\n",
    "    replyCount_tmp = []\n",
    "    commentSn_tmp = []\n",
    "\n",
    "    for num in range(len(com_list)):\n",
    "        try:\n",
    "\n",
    "\n",
    "            cc = com_list[num]['result']['comments']['comments']\n",
    "            article_id = list(map(lambda x: x['articleId'],cc))\n",
    "            user_id = list(map(lambda x: x['pictureUrl'],cc))\n",
    "            user_name = list(map(lambda x: x['displayName'],cc))\n",
    "            content = list(map(lambda x: x['contents'][0]['extData']['content'],cc))\n",
    "            commentSn = list(map(lambda x: x['commentSn'],cc))\n",
    "\n",
    "            like = []\n",
    "            dislike = []\n",
    "            replyCount = []\n",
    "\n",
    "            for i in range(len(com_list[num]['result']['comments']['comments'])):\n",
    "\n",
    "                try:    \n",
    "                    like = com_list[num]['result']['comments']['comments'][i]['ext']['likeCount']['up']\n",
    "                    like_tmp.append(like) \n",
    "                except KeyError:\n",
    "                    like_tmp.append(0) \n",
    "\n",
    "                try:\n",
    "                    dislike = com_list[num]['result']['comments']['comments'][i]['ext']['likeCount']['down']\n",
    "                    dislike_tmp.append(dislike)\n",
    "                except:\n",
    "                    dislike_tmp.append(0)\n",
    "\n",
    "                try:\n",
    "                    replyCount = com_list[num]['result']['comments']['comments'][i]['ext']['replyCount']\n",
    "                    replyCount_tmp.append(replyCount)\n",
    "                except:  \n",
    "                    replyCount_tmp.append(0)\n",
    "\n",
    "\n",
    "\n",
    "            article_id_tmp.append(article_id)\n",
    "            user_id_tmp.append(user_id)\n",
    "            user_name_tmp.append(user_name)\n",
    "            content_tmp.append(content)\n",
    "            commentSn_tmp.append(commentSn)\n",
    "\n",
    "            if num%500 == 0:\n",
    "                print(num)\n",
    "                \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    article_id_tmp = list(chain(*article_id_tmp))\n",
    "    user_id_tmp = list(chain(*user_id_tmp))\n",
    "    user_name_tmp = list(chain(*user_name_tmp))\n",
    "    content_tmp = list(chain(*content_tmp))\n",
    "    commentSn_tmp = list(chain(*commentSn_tmp))\n",
    "\n",
    "\n",
    "\n",
    "    tmp_dict = { 'article_id' : article_id_tmp,\n",
    "                 'user_id' : user_id_tmp,\n",
    "                 'user_name' : user_name_tmp,\n",
    "                 'comment' : content_tmp,\n",
    "                 'like' : like_tmp,\n",
    "                  'dislike' : dislike_tmp,\n",
    "                  'replyCount' : replyCount_tmp,\n",
    "                 'commentSn' : commentSn_tmp\n",
    "               }\n",
    "\n",
    "    comment_table = pd.DataFrame(tmp_dict)\n",
    "    comment_table['comment_id'] = comment_table['article_id'] + comment_table['commentSn']\n",
    "    \n",
    "    return comment_table, com_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "comment_table = build_table2()\n",
    "end = datetime.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table3():\n",
    "    \n",
    "    \"\"\" 獲得留言的回覆\n",
    "        1. article_id: 文章id\n",
    "        2. commentSn: 留言流水號\n",
    "        3. user_id: 回文作者照片\n",
    "        4. user_name: 回文作者名\n",
    "        5. comment: 回文內容 \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" 利用文章id和留言流水號建立回文的url\n",
    "    \"\"\"\n",
    "    url = 'https://api.today.line.me/webapi/comment/list?articleId=%s&limit=100&country=TW&parentCommentSn=%s'\n",
    "    filter = comment_table['replyCount'] > 0\n",
    "    reply_id = (comment_table[filter]['article_id'] + ',' +comment_table[filter]['commentSn']).values\n",
    "    reply_url_list = list(map(lambda x: url%tuple(x.split(',')), reply_id))\n",
    "    \n",
    "    print('url len:%s '%len(reply_url_list))\n",
    "    \"\"\" 拿到json檔\n",
    "    \"\"\"\n",
    "    reply_list = []\n",
    "    try:\n",
    "        for i in range(len(reply_url_list)):\n",
    "            tmp = requests.get(reply_url_list[i]).text\n",
    "            tmp = json.loads(tmp)\n",
    "            reply_list.append(tmp)\n",
    "            if i%500 == 0:\n",
    "                   print(i)\n",
    "    except:\n",
    "        print('x')\n",
    "\n",
    "    \"\"\" 從json檔中提取所要的資訊\n",
    "    \"\"\"\n",
    "    article_id_tmp = []\n",
    "    commentSn_tmp = []\n",
    "    user_name_tmp = []\n",
    "    user_id_tmp = []\n",
    "    comment_tmp = []\n",
    "\n",
    "    for i in range(len(reply_list)):\n",
    "        try:\n",
    "            \"\"\" 抓取所需要的資訊\n",
    "                檢查這一段\n",
    "            \"\"\"        \n",
    "            cc = reply_list[i]['result']['comments']['comments']\n",
    "            article_id = list(map(lambda x: x['articleId'], cc))\n",
    "            commentSn = list(map(lambda x: x['commentSn'], cc))\n",
    "            user_name = list(map(lambda x: x['displayName'], cc))\n",
    "            user_id = list(map(lambda x: x['pictureUrl'], cc))\n",
    "            comment = list(map(lambda x: x['contents'][0]['extData']['content'], cc))\n",
    "\n",
    "            article_id_tmp.append(article_id)\n",
    "            commentSn_tmp.append(commentSn)\n",
    "            user_name_tmp.append(user_name)\n",
    "            user_id_tmp.append(user_id)\n",
    "            comment_tmp.append(comment)\n",
    "            if i%500 == 0:\n",
    "                print(i)\n",
    "\n",
    "        except:\n",
    "            \n",
    "            continue\n",
    "\n",
    "    article_id_tmp = list(chain(*article_id_tmp))\n",
    "    user_id_tmp = list(chain(*user_id_tmp))\n",
    "    user_name_tmp = list(chain(*user_name_tmp))\n",
    "    content_tmp = list(chain(*comment_tmp))\n",
    "    commentSn_tmp = list(chain(*commentSn_tmp))\n",
    "\n",
    "    tmp_dict = {'article_id' : article_id_tmp,\n",
    "                'commentSn' : commentSn_tmp,\n",
    "                'user_id' : user_id_tmp,\n",
    "                'user_name' : user_name_tmp,\n",
    "                'comment' : content_tmp\n",
    "\n",
    "                }\n",
    "\n",
    "    reply_table = pd.DataFrame(tmp_dict)\n",
    "    reply_table['comment_id'] = reply_table['article_id'] + reply_table['commentSn']\n",
    "    \n",
    "    return reply_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "reply_table = build_table3()\n",
    "end = datetime.datetime.now()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to MSSQL\n",
    "* pip install sqlalchemy\n",
    "* pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mssql+pyodbc://sa:password@localhost:1433/linetoday?driver=SQL+Server+Native+Client+11.0\",echo=False)\n",
    "cate.to_sql('cate',engine,index=False,if_exists='append')\n",
    "reply_table.to_sql('reply',engine,index=False,if_exists='append')\n",
    "comment_table.to_sql('comment',engine,index=False,if_exists='append')\n",
    "content_table.to_sql('content',engine,index=False,if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'pyscraper'",
   "language": "python",
   "name": "pyscraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
